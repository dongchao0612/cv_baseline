# ImageNet Classification with Deep Convolutional Neural Networks

## 摘要

我们训练了一个大型的深卷积神经网络，将ImageNet LSVRC-2010竞赛中的120万张高分辨率图像分类为1000个不同的类别。在测试数据上，我们获得了前1名和前5名的错误率分别为37.5%和17.0%，远远好于以前的最先进水平。该神经网络具有6000万个参数和65万个神经元，由五个卷积层组成，其中一些卷积层之后是最大值池化层，以及三个完全连通的层，最后是1000路Softmax。为了使训练速度更快，我们使用了非饱和神经元和非常高效的卷积运算的GPU实现。为了减少在完全连通的层中的过拟合，我们采用了一种最近开发的被证明非常有效的正则化方法，称为“Dropout”。我们还在ILSVRC-2012比赛中加入了该模型的一个变体，并获得了15.3%的前5名测试错误率，而第二好的参赛者的错误率为26.2%。

## 1. PROLOGUE

四年前，扬·勒昆和他的合作者的一篇论文被领先的计算机视觉会议拒绝，理由是该论文使用了神经网络，因此没有提供如何设计视觉系统的见解。当时，大多数计算机视觉研究人员认为，视觉系统需要通过对任务性质的详细理解来仔细手工设计。他们假设，对自然图像中的对象进行分类的任务永远不会通过简单地将图像示例及其包含的对象名称呈现给神经网络来解决，神经网络从这些训练数据中获取所有知识。

视觉研究界的许多人没有意识到的是，需要了解该领域的程序员仔细地手工设计的方法不能扩展，也不能像用强大的通用学习过程取代程序员的方法那样规模化。有了足够的计算和足够的数据，对于复杂的任务来说，学习胜过编程，因为复杂的任务需要集成许多不同的、噪声的提示。

四年前，当我们还在多伦多大学时，我们被称为监督的深度神经网络几乎将自然图像中物体识别的错误率降低了一半，并引发了计算机视觉领域早该发生的范式转变。图4显示了监督功能的一些示例。

![img](https://cdn.nlark.com/yuque/0/2022/png/26510486/1656984866405-a0952db4-0020-4f62-9372-2ff1b1de1426.png)

监督是由多层神经网络演化而来的，在20世纪80年代得到了广泛的调查。这些网络使用了多层特征检测器，这些特征检测器都是从训练数据中学习的。神经学家和心理学家曾假设，这种特征探测器的层级结构将提供一种识别物体的强大方法，但他们不知道如何学习这样的层级结构。在20世纪80年代，因为几个不同的研究小组发现多层特征检测器可以被称为反向传播，来计算每个图像的整个网络的分类性能如何依赖于每个连接上的权值，所以引起了极大的兴奋。

反向传播在各种任务中发挥了很好的作用，但在20世纪80年代，它没有达到倡导者非常高的期望。特别是，事实证明，学习具有多个层的网络非常困难，而这些正是应该给出最令人印象深刻的结果的网络。许多研究人员错误地得出结论，认为从随机初始权重学习深度神经网络太难了。20年后，我们知道哪里出了问题：为了让深度神经网络大放异彩，它们需要更多的标签数据和大量的计算。

## 2. INTRODUCTION

当前的目标识别方法主要使用机器学习方法。为了提高它们的性能，我们可以收集更大的数据集，学习更强大的模型，并使用更好的技术来防止过度拟合。直到最近，标记图像的数据集还相对较小--数万张图像。使用这种大小的数据集可以很好地解决简单的识别任务，特别是如果用保持标签的变换来增强它们的话。例如，MNIST数字识别任务的当前最佳错误率(<0.3%)接近人类表现。但现实环境中的对象表现出相当大的可变性，因此要学习识别它们，有必要使用更大的训练集。事实上，小图像数据集的缺点已被广泛认识，但直到最近才有可能收集数百万个标记的数据集图像。新的更大的数据集包括LabelMe 28和ImageNet 7，LabelMe 28由数十万张完全分割的图像组成，ImageNet 7由22,000多个类别的1500多万张带标签的高分辨率图像组成。

要从数以百万计的图像中了解数以千计的物体，我们需要一个具有大学习能力的模型。然而，对象识别任务的巨大复杂性意味着即使是像ImageNet这样大的数据集也不能指定这个问题，所以我们的模型也应该有很多先验知识来补偿我们没有的所有数据。卷积神经网络(CNN)构成了一类这样的模型，它们的容量可以通过改变它们的深度和广度来控制，它们还对图像的性质(即统计的平稳性和像素相关性的局部性)做出了强有力且基本上正确的假设。因此，与具有类似大小的层的标准前向神经网络相比，CNN具有更少的连接和参数，因此它们更容易训练，而它们在理论上的最佳性能可能仅略差。

尽管CNN具有吸引人的特性，尽管其本地结构相对高效，但将其大规模应用于高分辨率图像仍然昂贵得令人望而却步。幸运的是，当前的GPU，加上高度优化的2D卷积实现，足以促进感兴趣的大型CNN的训练，并且最近的数据集，如ImageNet，包含足够的标记样本来训练这样的模型，而不会出现严重的过拟合。

本文的具体贡献如下：我们在ImageNet大规模视觉识别挑战(ILSVRC)-2010和ILSVRC-2012比赛中使用的ImageNet子集上训练了迄今为止最大的CNN之一，并在这些数据集上取得了迄今为止最好的结果。我们编写了2D卷积和训练CNN中固有的所有其他操作的高度优化的GPU实现，并将其公开提供。A我们的网络包含许多新的和不寻常的功能，这些功能改善了它的性能并减少了它的训练时间，这在第4节中有详细的描述。我们的网络的规模使得过度拟合成为一个严重的问题，即使有120万个标记的训练样本，所以我们使用了几种有效的技术来防止过度拟合，这些技术在第5节中进行了描述。我们最终的网络包含五个卷积层和三个完全连通的层，这个深度似乎很重要：我们发现删除任何卷积层(每个层包含的模型参数不超过1%)会导致性能下降。

归根结底，网络的大小主要受到当前GPU上可用内存量和我们愿意容忍的训练时间的限制。我们的网络在两个GTX 580 3 GB GPU上进行培训需要5到6天的时间。我们的所有实验都表明，只要等待更快的GPU和更大的数据集出现，我们的结果就可以得到改善。

## 3. THE DATASET

ImageNet是一个包含1500多万张标签的高分辨率图像的数据集，属于大约22,000个类别。这些图像是从网络上收集的，并于2010年由人类标记员usingAmazon‘sMechanicalTurkcrowd-sourcingtool.Starting标记，除了PascalVisualObject挑战赛外，还举行了一年一度的比赛，称为ImageNet大规模视觉识别挑战赛(ILSVRC)。ILSVRC使用ImageNet的一个子集，在1000个类别中的每个类别中都有大约1000个图像。总共大约有120万个训练图像、50,000个验证图像和150,000个测试图像。

ILSVRC-2010是唯一提供测试集标签的ILSVRC版本，因此这是我们执行大多数实验的版本。由于我们还在ILSVRC-2012比赛中输入了我们的模型，因此在第7节中，我们也报告了在此版本的数据集上的结果，其中测试集标签不可用。在ImageNet上，通常报告两个错误率：Top-1和Top-5，其中top-5错误率是正确标签不在模型认为最有可能的五个标签中的测试图像的分数。

ImageNet由可变分辨率的图像组成，而我们的系统需要恒定的输入维度。因此，我们将图像下采样到256×256的固定分辨率。给定一个矩形图像，我们首先对图像进行重新缩放，使较短的边的长度为256，然后从生成的图像中裁剪出中心的256×256面片。除了从每个像素减去训练集上的平均活跃度外，我们没有以任何其他方式对图像进行预处理。因此，我们在像素的原始RGB值(居中)上训练网络。

## 4. THE ARCHITECTURE

我们的网络体系结构如图2所示。它包含八个学习层--五个卷积层和三个完全连接层。下面，我们将介绍我们网络体系结构的一些新颖或不同寻常的功能。4.1-4.4节是根据我们对其重要性的估计进行排序的，最重要的排在第一位。

![img](https://cdn.nlark.com/yuque/0/2022/png/26510486/1656985915416-e6f8dd34-48c0-424c-827b-4f75f56f3148.png)

### 4.1. Rectified Linear Unit nonlinearity

对神经元![img](https://cdn.nlark.com/yuque/__latex/712ecf7894348e92d8779c3ee87eeeb0.svg)的输出![img](https://cdn.nlark.com/yuque/__latex/18f3c2855f0e85a1ac2257f64d917144.svg)建模的标准方法是![img](https://cdn.nlark.com/yuque/__latex/5bb5b6931793f8c0c169e29499a0fda5.svg)或![img](https://cdn.nlark.com/yuque/__latex/44bb40394883408c50a3a37e1f926935.svg)。就梯度下降的训练时间而言，这些饱和非线性比非饱和非线性![img](https://cdn.nlark.com/yuque/__latex/9a30e8e7daa8c77426f6bcb368037cb1.svg)慢得多。在Nair和Hinton之后，24我们将具有这种非线性的神经元称为整流线性单位(RELU)。具有RELU的深度CNN的训练速度比具有TANH单元的等价物快几倍。图1展示了这一点，它显示了对于特定的四层卷积网络，在CIFAR-10数据集上达到25%训练误差所需的迭代次数。这张图表明，如果我们使用传统的饱和神经元模型，我们不可能在这项工作中试验如此大的神经网络。

![img](https://cdn.nlark.com/yuque/0/2022/png/26510486/1656986195343-399a7909-54f7-41ab-9e94-eb1b6597f6d3.png)

我们并不是第一个考虑在CNN中替代传统神经元模型的人。例如，Jarrett等人声称非线性函数![img](https://cdn.nlark.com/yuque/__latex/c5c680daeb29c98e5ac6a17025ef22b2.svg)在对比度归一化和局部归一化的情况下工作得特别好的平均池化在Caltech-101数据集。然而，在这个数据集上，主要关注的是防止过度拟合，所以他们观察到的效果与我们使用ReLU时报告的加速适应训练集的能力不同。更快的学习速度对在大数据集上训练的大型模型的性能有很大影响。

### 4.2. Training on multiple GPUs

单个GTX 580图形处理器只有3 GB的内存，这限制了可以在其上训练的网络的最大大小。事实证明，120万个训练样本足以训练太大而不能在一个GPU上容纳的网络。因此，我们将网络分布在两个GPU上。当前的GPU特别适合跨GPU并行化，因为它们能够直接从彼此的内存中读取和写入，而不需要通过主机内存。我们使用的并行化方案基本上将一半的内核(或神经元)放在每个GPU上，还有一个额外的技巧：GPU只在特定的层进行通信。这意味着，例如，第3层的内核从第2层的所有内核映射获取输入。但是，第4层的内核仅从驻留在同一GPU上的第3层的内核映射获取输入。选择连接模式是交叉验证的一个问题，但这使我们可以精确地调整通信量，直到它达到计算量的可接受部分。

结果得到的体系结构与CireşAn等人使用的“柱状”cnn有些相似，不同之处在于我们的列不是独立的(参见图2)。与在一个GP上训练的每个卷积层中具有一半核的网络相比，该方案分别将TOP-1和TOP-5的错误率降低1.7%和1.2%，Two-GPU训练时间略短于One-GPU。

### 4.3. Local response normalization

RELU具有所需的特性，即它们不需要输入规格化来防止它们饱和。如果至少有一些训练样本产生了对REU的正输入，那么该神经元就会发生学习。然而，我们仍然发现下面的局部归一化方案有助于推广。用![img](https://cdn.nlark.com/yuque/__latex/584525ff6cfcfe83a6a22f3beec2d1bd.svg)表示通过在位置![img](https://cdn.nlark.com/yuque/__latex/aa5b8e2df3dcaa6b5c74ea7e0e07c721.svg)应用核![img](https://cdn.nlark.com/yuque/__latex/2443fbcfeb7e85e1d62b6f5e4f27207e.svg)并然后应用REU非线性来计算神经元的活动，响应归一化活动![img](https://cdn.nlark.com/yuque/__latex/73b2cddb9e872249d3e51b8e027eb759.svg)由以下表达式给出

![img](https://cdn.nlark.com/yuque/__latex/5630d4176b2b210f6a93d48338962f98.svg)

其中，该和在相同空间位置的n个“相邻”核映射上运行，N是层中的核的总数。当然，核映射的排序是任意的，并且在训练开始之前确定。这种反应标准化实现了一种侧抑制形式，灵感来自于在真实神经元中发现的类型，在使用不同核计算的神经元输出之间创造了对大活动的竞争。常量k、n、α和β是使用验证集确定其值的超参数；我们使用k=2、n=5、α=10−4和β=0.75.在某些层中应用REU非线性之后，我们应用了此归一化(参见第4.5节)。

这个方案与Jarrett等人的局部对比度归一化方案有一些相似之处，但我们的方案应该更准确地命名为“亮度归一化”，因为我们没有减去平均活度。响应标准化将前1名和前5名的错误率分别降低了1.4%和1.2%。我们还在CIFAR-10数据集上验证了该方案的有效性：一个四层CNN获得了13%的无normalization测试错误率和 1 1%的有normalization测试错误率。

### 4.4. Overlapping pooling

CNN中的池化层汇总了同一核映射中相邻神经元组的输出。传统上，由相邻池单元总结的邻区不重叠。更准确地说，池化层可以被认为是由间隔s个像素的池化单元的网格组成，每个网格汇总大小为z×z的邻域，该邻域的大小以该池化单元的位置为中心。如果我们设置=z，我们就得到了CNN中通常使用的传统局部池。如果我们设置s<z，则得到重叠池化。这就是我们在整个网络中使用的，其中s=2和z=3。与非重叠方案s=2，z=2相比，该方案分别将TOP-1和TOP-5的错误率降低0.4%和0.3%，后者产生相同维度的输出。我们通常在培训期间观察到，具有重叠池的模型会发现稍微更难过度适应。

### 4.5. Overall architecture

现在我们准备好描述我们CNN的整体架构。如图2所示，该网络包含八个带权重的层；前五层是卷积的，其余三层是完全连接的。最后一个完全连接的层的输出被馈送到1000路Softmax，它产生在1000个类别标签上的分布。我们的网络最大化多项Logistic回归目标，这等价于最大化预测分布下正确标签的对数概率的跨训练用例的平均值。

第二、第四和第五卷积层的内核仅连接到驻留在同一GPU上的上一层中的那些内核贴图(参见图2)。第三卷积层的核连接到第二层中的所有核映射。完全连通的层中的神经元连接到前一层中的所有神经元。响应归一化层位于第一卷积层和第二卷积层之后。第4.4节中描述的那种最大池化层既在响应归一化层之后，也在第五卷积层之后。将RELU非线性应用于每个卷积层和完全连接层的输出。

第一卷积层对具有96个核的224×224×3输入图像进行滤波，核的大小为11×11×3，步长为4个像素(这是核图中相邻神经元的感受场中心之间的距离)。第二卷积层将第一卷积层的(响应归一化和池化)输出作为输入，并用256个大小为5×5×48的核对其进行滤波。第三卷积层、第四卷积层和第五卷积层彼此连接，而没有任何中间的合并层或归一化层。第三卷积层有384个大小为3×3×256的核连接到(归一化、池化)输出第二卷积层。第四卷积层有384个核，大小为3×3×192，第五卷积层有256个核，大小为3×3×192。完全连通的每一层都有4096个神经元。

## 5. REDUCING OVERFITTING

我们的神经网络结构有6000万个参数。尽管ILSVRC的1000个类使得每个训练样本对从图像到标签的映射施加了10比特的约束，但事实证明，这不足以学习如此多的参数而不进行相当大的过拟合。下面，我们将描述我们对抗过度适应的两种主要方式。

### 5.1. Data augmentation

减少图像数据上的过度适配的最简单和最常见的方法是使用保持标签的变换人为地放大数据集。我们采用了两种不同的数据增强形式，这两种形式都允许以非常少的计算从原始图像生成转换后的图像，因此转换后的图像不需要存储在磁盘上。在我们的实现中，转换后的图像是在CPU上以Python代码生成的，而GPU正在对前一批图像进行训练。因此，这些数据增强方案实际上是不需要计算的。

第一种形式的数据增强包括生成图像平移和水平反射。为此，我们从256×256图像中提取随机的224×224块(及其水平反射)，并在这些提取的块上训练我们的网络。这使我们的训练集的大小增加了2048倍，尽管产生的训练样本当然是高度相互依赖的。如果没有这个计划，我们的网络将遭受严重的过度安装，这将迫使我们使用小得多的网络。在测试时，网络通过提取5个224×224个patch(4个角面片和中心面片)以及它们的水平反射(因此总共10个面片)来进行预测，并对网络的Softmax层在这10个面片上所做的预测进行平均。

第二种形式的数据增强包括改变训练图像中RGB通道的强度。具体地说，我们在整个ImageNet训练集中对RGB像素值集合执行PCA。对于每个训练图像，我们将所找到的主分量的倍数相加，其大小与相应的特征值乘以从均值为0且标准差为0.1的高斯提取的随机变量成比例。因此，对于每个RGB图像像素![img](https://cdn.nlark.com/yuque/__latex/9ecca6775030b8f40c2bf5edd81466c9.svg)，我们添加以下量

![img](https://cdn.nlark.com/yuque/__latex/b42e6012850558d63dae01171b991147.svg)

其中，p_i和![img](https://cdn.nlark.com/yuque/__latex/4835f2ad1f09fde608022ea9360e93e1.svg)分别是rgb像素值的3×3协方差矩阵的第![img](https://cdn.nlark.com/yuque/__latex/2443fbcfeb7e85e1d62b6f5e4f27207e.svg)个特征向量和特征值，并且![img](https://cdn.nlark.com/yuque/__latex/a7df4056aa232672fe6041f972679c0f.svg)是前述随机变量。对于特定训练图像的所有像素，仅绘制一次每个![img](https://cdn.nlark.com/yuque/__latex/a7df4056aa232672fe6041f972679c0f.svg)，直到该图像被再次用于训练，此时它被重新绘制。该方案近似地捕捉到了自然图像的一个重要特性，即目标身份不随光照强度和颜色的变化而变化。该方案将TOP-1误码率降低了1%以上。

### 5.2. Dropout

组合许多不同模型的预测是一种非常成功的减少测试误差的方法，但对于已经需要几天时间训练的大型神经网络来说，这似乎太昂贵了。然而，有一种非常有效的模型组合版本，在培训期间只需花费大约两倍的成本。最近引入的这项技术被称为“丢弃”，包括将概率为0.5的每个隐藏神经元的输出设置为零。以这种方式“退出”的神经元不参与前向传递，也不参与后向传播。因此，每次提供输入时，神经网络都会对不同的体系结构进行采样，但所有这些体系结构都会共享权重。这项技术减少了神经元复杂的共同适应，因为一个神经元不能依赖于特定其他神经元的存在。因此，它被迫学习更健壮的特征，这些特征与其他神经元的许多不同的随机子集一起是有用的。在测试时，我们使用所有神经元，但将其输出乘以0.5，这是一个合理的近似，取指数多次辍学网络产生的预测分布的几何平均值。

我们在图2的前两个完全连接的层中使用了丢弃。如果没有丢弃，我们的网络将显示出严重的过度匹配。丢弃使收敛所需的迭代次数增加了一倍。

## 6. DETAILS OF LEARNING

我们使用随机梯度下降来训练我们的模型，批次大小为128个例子，动量为0.9，权重衰减为0.0005。我们发现，这种少量的重量衰减对模型学习很重要。换句话说，这里的权重衰减不仅仅是正则化的：它减少了模型的训练误差。权重![img](https://cdn.nlark.com/yuque/__latex/c9b08ae6d9fed72562880f75720531bc.svg)的更新规则是

![img](https://cdn.nlark.com/yuque/__latex/4425f63bf8c2cde5de2dc4c1489d8414.svg)

其中![img](https://cdn.nlark.com/yuque/__latex/2443fbcfeb7e85e1d62b6f5e4f27207e.svg)是迭代指数，![img](https://cdn.nlark.com/yuque/__latex/a770a282bbfa0ae1ec474b7ed311656d.svg)是动量变量，![img](https://cdn.nlark.com/yuque/__latex/7c102e7a7d231bf935f9bc23417779a8.svg)是学习速率，并且![img](https://cdn.nlark.com/yuque/__latex/f47ef0f303ba9d9f4f2ac96f6df77277.svg)是对象关于w的导数的第![img](https://cdn.nlark.com/yuque/__latex/2443fbcfeb7e85e1d62b6f5e4f27207e.svg)批次![img](https://cdn.nlark.com/yuque/__latex/f47ef0f303ba9d9f4f2ac96f6df77277.svg)的平均值，在![img](https://cdn.nlark.com/yuque/__latex/d99fd2df7b5f652a4b7fc593fb9df750.svg)处评估。

我们从标准差为0.01的零均值高斯分布中初始化每一层中的权重。我们用常数1初始化了第二、第四和第五卷积层以及完全连接的隐藏层中的神经元偏置。这种初始化通过为ReLU提供正输入来加速学习的早期阶段。我们用常量0来初始化剩余层中的神经元偏向。

我们对所有层使用相同的学习率，并在整个培训过程中手动调整。我们遵循的启发式方法是，当验证错误率不再随着当前学习率的提高而提高时，将学习率除以10。学习速率被初始化为0.01，并在终止前降低三次。我们通过120万张图像的训练集对网络进行了大约90个周期的训练，在两个NVIDIA GTX 580 3 GB GPU上进行了5-6天的训练。

## 7. RESULTS

表1总结了我们在ILSVRC-2010上的结果。我们的网络获得了前1名和前5名的测试集错误率，分别为37.5%和17.0%。在ILSVRC-2010比赛期间，使用一种平均六个稀疏编码模型对不同特征训练产生的预测的方法，获得的最好性能分别为471%和28.2%，2此后发表的最好结果分别为45.7%和25.7%，其方法是平均两种密集采样特征计算的基于Fisher向量(FV)的两个分类器的预测。

我们还在ILSVRC-2012竞赛中加入了我们的模型，并在表2中报告了我们的结果。由于ILSVRC-2012测试集标签不公开，因此我们不能报告我们训练过的错误率。

在本段落的其余部分中，我们交替使用验证错误率和测试错误率，因为根据我们的经验，它们的差异不超过0.1%(参见表2)。本文描述的CNN达到了18.2%的前5名错误率。对五个相似的CNN进行平均预测，错误率为16.4%。训练一个CNN，在最后一层上增加一个第六卷积层，以对整个ImageNet 2011年秋季版本(1500万张图像，22000个类别)进行分类，然后在ILSVRC-2012上对其进行“微调”，错误率为16.6%。使用上述五个CNN对两个针对整个2011秋季版本进行预训练的CNN进行平均预测，错误率为15.3%。第二好的参赛作品获得了26.2%的错误率，其方法是对从不同类型的密集采样特征计算出的FV训练的几个分类器的预测进行平均。

最后，我们还报告了我们在2009年秋季版本的ImageNet上的错误率，该版本有10,184个类别和890万张图像。在这个数据集上，我们遵循文献中的惯例，将一半的图像用于训练，另一半用于测试。由于没有建立测试集，因此我们的拆分必然与以前作者使用的拆分不同，但这不会对结果产生明显影响。我们在此数据集上的前1和前5错误率分别为67.4%和40.9%，这是通过上述网络实现的，但在最后一个池层上增加了第六卷积层。在此数据集上发布的最佳结果为78.1%和60.9%。

### 7.1. Qualitative evaluations

图3显示了由网络的两个数据连接层学习的卷积内核。该网络已经学习了各种频率和方向选择核，以及各种颜色的斑点。请注意两个GPU表现出的专业化，这是第4.5节中描述的受限连接的结果。GPU 1上的内核在很大程度上与颜色无关，而GPU 2上的内核在很大程度上是特定颜色。这种专门化在每次运行期间发生，并且独立于任何特定的随机权重初始化(对GPU的重新编号取模。

在图4的左面板中，我们通过计算8个测试图像的前5个预测来定性地评估网络了解到了什么。请注意，即使是偏离中心的对象，如左上角的螨虫，也可以被网络识别。排名前五的大多数标签看起来都是合理的。例如，只有其他类型的猫才被认为是豹子的合理标签。在某些情况下(格栅、樱桃色)，照片的目标焦点确实含糊不清。

探索网络视觉知识的另一种方式是考虑图像在最后4096维隐藏层诱导的特征激活。如果两个图像产生欧氏距离较小的特征激活向量，我们可以说较高级别的神经网络认为它们是相似的。图4显示了来自测试集的五个图像和来自训练集中的六个图像，根据该度量，这些图像与它们中的每一个最相似。注意，在像素级，检索到的训练图像在L2中通常不接近第一列中的查询图像。例如，取回的狗和大象以各种形式出现摆姿势。我们在补充材料中给出了更多测试图像的结果。

![img](https://cdn.nlark.com/yuque/0/2022/png/26510486/1656988099198-cb0da417-3282-47c1-adbb-18934d995804.png)

通过使用两个4096维实值向量之间的欧几里德距离来计算相似性是低效的，但是可以通过训练自动编码器将这些向量压缩成短的二进制码来提高效率。这应该产生比对原始像素应用自动编码器好得多的图像检索方法，这不利用图像标签，因此具有检索具有相似边缘图案的图像的趋势，无论它们在语义上是否相似。

## 8. DISCUSSION

我们的结果表明，一个大的、深度的CNN能够在一个具有高度挑战性的数据集上使用纯监督学习获得创纪录的结果。值得注意的是，如果去掉单个卷积层，我们的网络性能就会下降。例如，删除任何中间层都会导致网络的TOP-1性能损失约2%。所以深度对取得我们的结果非常重要。

为了简化我们的实验，我们没有使用任何无监督的预训练，尽管我们期望它会有所帮助，特别是如果我们获得足够的计算能力，显著增加网络的大小，而不获得相应的标记数据量的增加。到目前为止，我们的结果已经有所改善，因为我们已经使我们的网络更大，训练它更长，但我们仍然有许多数量级要去匹配人类视觉系统的地狱时间路径。最终，我们希望在视频序列上使用非常大和深度的卷积网络，其中时间结构重新提供非常有用的信息，即在静态图像中缺失或不太明显。

## 9. EPILOGUE

计算机视觉社区对监管的成功反应令人印象深刻。在接下来的一两年里，他们转而使用深度神经网络，现在谷歌、Facebook、微软、百度和许多其他公司都广泛使用了这些网络。到2015年，更好的硬件、更多的隐藏层和一系列技术进步将深度卷积神经网络的错误率进一步降低了三倍，因此它们现在非常接近人类对静态图像的表现。这场革命的大部分功劳应该归功于花了很多年开发CNN技术的先驱们，但基本缺失的成分是由Feifei等人提供的。他们投入了巨大的努力来产生一个标记的数据集，这个数据集最终足够大，足以显示神经网络的真正功能。